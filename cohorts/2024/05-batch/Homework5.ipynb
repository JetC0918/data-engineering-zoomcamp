{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75b6063-017f-460e-aa5b-b178079a68a5",
   "metadata": {},
   "source": [
    "## Module 5 Homework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e8fe9-e0ed-4955-b96a-296895238259",
   "metadata": {},
   "source": [
    "#### Question 2:\r\n",
    "FHV October 2019\r\n",
    "\r\n",
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\r\n",
    "\r\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ee444a-cd0b-4948-a832-c4830bb791af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9912d87c-987b-4ac6-b4bc-8dd23e393fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3aab316-023a-49f1-87c5-79828e56a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"fhv_tripdata_2019-10.csv.gz\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"File downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70247867-c9a2-4d12-865f-76136824f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c4f382-5a31-4083-a7b7-44bf090e8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv_pd = pd.read_csv('fhv_tripdata_2019-10.csv.gz', nrows = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9154e242-7a76-477a-9f5f-b75badd9faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:54:57</td>\n",
       "      <td>2019-10-01 03:10:06</td>\n",
       "      <td>264.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:07:06</td>\n",
       "      <td>2019-10-01 01:29:54</td>\n",
       "      <td>264.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>B00112</td>\n",
       "      <td>2019-10-01 01:05:36</td>\n",
       "      <td>2019-10-01 01:36:28</td>\n",
       "      <td>264.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>B00160</td>\n",
       "      <td>2019-10-01 01:20:00</td>\n",
       "      <td>2019-10-01 01:26:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>B00225</td>\n",
       "      <td>2019-10-01 01:15:03</td>\n",
       "      <td>2019-10-01 01:22:57</td>\n",
       "      <td>264.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                 B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1                 B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2                 B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3                 B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4                 B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "..                   ...                  ...                  ...   \n",
       "995               B00111  2019-10-01 01:54:57  2019-10-01 03:10:06   \n",
       "996               B00111  2019-10-01 01:07:06  2019-10-01 01:29:54   \n",
       "997               B00112  2019-10-01 01:05:36  2019-10-01 01:36:28   \n",
       "998               B00160  2019-10-01 01:20:00  2019-10-01 01:26:00   \n",
       "999               B00225  2019-10-01 01:15:03  2019-10-01 01:22:57   \n",
       "\n",
       "     PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           264.0         264.0      NaN                 B00009  \n",
       "1           264.0         264.0      NaN                 B00013  \n",
       "2           264.0         264.0      NaN                 B00014  \n",
       "3           264.0         264.0      NaN                 B00014  \n",
       "4           264.0         264.0      NaN                 B00014  \n",
       "..            ...           ...      ...                    ...  \n",
       "995         264.0         100.0      NaN                 B00111  \n",
       "996         264.0         188.0      NaN                 B00111  \n",
       "997         264.0         228.0      NaN                 B00112  \n",
       "998         264.0         264.0      NaN                 B00160  \n",
       "999         264.0         232.0      NaN                 B00225  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bda49816-d9e6-452f-8e59-b1eaad9c452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_fhv_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6139d804-481f-42de-9afe-9251081b9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04b7867a-3a17-4084-910a-805f21e9bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.DoubleType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d5fc4ba-c664-45ed-b95c-de67c88d3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhv_schema)\\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d946e9f-ef5f-46de-8d31-848d3d3dfa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropOff_datetime', TimestampType(), True), StructField('PUlocationID', IntegerType(), True), StructField('DOlocationID', IntegerType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71b3c7e-143f-45ee-b87d-aa3450488c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path =  'data/pq/fhv/2019/10/'\n",
    "\n",
    "df_fhv.repartition(6).write.parquet(output_path, mode=\"Overwrite\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b46e5dc-5c56-447a-a0d5-e0d4db5479ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average file size of the Parquet files are :6.4mb.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = 'data/pq/fhv/2019/10/'\n",
    "\n",
    "def get_avg_parquet_files_size(folder_path):\n",
    "    total_size = 0\n",
    "    file_num = 0\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.parquet'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "            file_num += 1\n",
    "    return (total_size/file_num)/1024/1024\n",
    "\n",
    "size = round(get_parquet_files_size(file_path),1)\n",
    "\n",
    "print (f'The average file size of the Parquet files are :{size}mb.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa552aa-b31b-4265-bafe-ae34724f8096",
   "metadata": {},
   "source": [
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "6mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32135621-af6e-4b86-960b-c04b904cc4e9",
   "metadata": {},
   "source": [
    "#### Question 3:\r\n",
    "\n",
    "Count records\r\n",
    "\r\n",
    "How many taxi trips were there on the 15th of October?\r\n",
    "\r\n",
    "Consider only trips that started on the 15th of October."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "472de518-c084-4263-981f-ca62a53072be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crab\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_fhv.registerTempTable('fhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "744ca8c1-1ff8-416e-938c-33039c58c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   NULL|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   NULL|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   NULL|       B00021         |\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM fhv_data  \n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7f0116a-ccb4-4171-b404-b39bbb49133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   62610|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(*) FROM fhv_data \n",
    "WHERE date(pickup_datetime) = '2019-10-15'\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471fa43-738b-4b83-9984-069ebb339926",
   "metadata": {},
   "source": [
    "62610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2075f55-9e67-4b9a-9789-e6e35fff1426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+\n",
      "|    pickup_datetime|   dropOff_datetime|  duration|\n",
      "+-------------------+-------------------+----------+\n",
      "|2019-10-11 18:00:00|2091-10-11 18:30:00|2272149000|\n",
      "|2019-10-28 09:00:00|2091-10-28 09:30:00|2272149000|\n",
      "|2019-10-31 23:46:33|2029-11-01 00:13:00| 315620787|\n",
      "|2019-10-01 21:43:42|2027-10-01 21:45:23| 252460901|\n",
      "|2019-10-17 14:00:00|2020-10-18 00:00:00|  31658400|\n",
      "|2019-10-26 21:26:00|2020-10-26 21:36:00|  31623000|\n",
      "|2019-10-30 12:30:04|2019-12-30 13:02:08|   5272324|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:54:33|   3804576|\n",
      "|2019-10-25 07:04:57|2019-12-08 07:21:11|   3802574|\n",
      "|2019-10-01 13:47:17|2019-11-03 15:20:28|   2856791|\n",
      "|2019-10-01 07:21:12|2019-11-03 08:44:21|   2856189|\n",
      "|2019-10-01 13:41:00|2019-11-03 14:58:51|   2855871|\n",
      "|2019-10-01 18:43:20|2019-11-03 19:43:13|   2854793|\n",
      "|2019-10-01 18:43:46|2019-11-03 19:43:04|   2854758|\n",
      "|2019-10-01 07:07:09|2019-11-03 07:58:46|   2854297|\n",
      "|2019-10-01 14:49:28|2019-11-03 15:38:07|   2854119|\n",
      "|2019-10-01 05:36:30|2019-11-03 06:23:36|   2854026|\n",
      "|2019-10-01 15:02:55|2019-11-03 15:49:05|   2853970|\n",
      "|2019-10-01 06:08:01|2019-11-03 06:53:15|   2853914|\n",
      "|2019-10-01 06:41:17|2019-11-03 07:26:04|   2853887|\n",
      "+-------------------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import  unix_timestamp\n",
    "\n",
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    pickup_datetime,\n",
    "    dropOff_datetime,\n",
    "\n",
    "    (unix_timestamp(dropOff_datetime) - unix_timestamp(pickup_datetime)) AS duration\n",
    "FROM\n",
    "    fhv_data\n",
    "ORDER BY\n",
    "    duration DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c228c7eb-e41f-4d87-8035-f478f3901e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631152.5\n"
     ]
    }
   ],
   "source": [
    "duration_seconds = 2272149000\n",
    "duration_hours = duration_seconds / 3600\n",
    "print(duration_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac25fc-a441-416d-9b3b-d9785e4854b9",
   "metadata": {},
   "source": [
    "631,152.50 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0240089-e68b-4dce-a345-c09769999431",
   "metadata": {},
   "source": [
    "#### Question 5:\n",
    "User Interface\n",
    "\n",
    "Sparkâ€™s User Interface which shows the application's dashboard runs on which local port?\n",
    " \n",
    "4040 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769064e0-001b-4be2-a1db-f40937bdfc19",
   "metadata": {},
   "source": [
    "#### Question 6:\n",
    "Least frequent pickup location zone\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark \n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "079519f2-e926-4929-93af-01e342d949b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"taxi_zone_lookup.csv\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"File downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9945a6b3-02bb-4548-9b7a-c5a48005c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone_pd = pd.read_csv('taxi_zone_lookup.csv', nrows = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31db25b7-1313-40fe-b977-79c6a852967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID        Borough                     Zone service_zone\n",
       "0             1            EWR           Newark Airport          EWR\n",
       "1             2         Queens              Jamaica Bay    Boro Zone\n",
       "2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3             4      Manhattan            Alphabet City  Yellow Zone\n",
       "4             5  Staten Island            Arden Heights    Boro Zone\n",
       "..          ...            ...                      ...          ...\n",
       "260         261      Manhattan       World Trade Center  Yellow Zone\n",
       "261         262      Manhattan           Yorkville East  Yellow Zone\n",
       "262         263      Manhattan           Yorkville West  Yellow Zone\n",
       "263         264        Unknown                       NV          NaN\n",
       "264         265        Unknown                      NaN          NaN\n",
       "\n",
       "[265 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zone_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cd7671d-3997-4d0e-948d-5f38f6739c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|PUlocationID|count_zone|\n",
      "+------------+----------+\n",
      "|           2|         1|\n",
      "|         105|         2|\n",
      "|         111|         5|\n",
      "|          30|         8|\n",
      "|         120|        14|\n",
      "|          12|        15|\n",
      "|         207|        23|\n",
      "|          27|        25|\n",
      "|         154|        26|\n",
      "|           8|        29|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " \n",
    "spark.sql(\"\"\"\n",
    "SELECT PUlocationID, COUNT(*) AS count_zone\n",
    "FROM fhv_data  \n",
    "GROUP BY PUlocationID\n",
    "ORDER BY count_zone\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1eaa64b0-233c-434f-bc65-4c160b6ff29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "148e68c3-0b88-4648-91ca-4b309ec95c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crab\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zone.registerTempTable('zone_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cafcd4a6-d67a-4af0-b947-6e700f0c55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+--------------------+\n",
      "|PUlocationID|count_zone|                Zone|\n",
      "+------------+----------+--------------------+\n",
      "|           2|         1|         Jamaica Bay|\n",
      "|         105|         2|Governor's Island...|\n",
      "|         111|         5| Green-Wood Cemetery|\n",
      "|          30|         8|       Broad Channel|\n",
      "|         120|        14|     Highbridge Park|\n",
      "|          12|        15|        Battery Park|\n",
      "|         207|        23|Saint Michaels Ce...|\n",
      "|          27|        25|Breezy Point/Fort...|\n",
      "|         154|        26|Marine Park/Floyd...|\n",
      "|           8|        29|        Astoria Park|\n",
      "+------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT f.PUlocationID, COUNT(*) AS count_zone, z.Zone \n",
    "FROM fhv_data f\n",
    "JOIN zone_data z ON f.PUlocationID = z.LocationID\n",
    "GROUP BY f.PUlocationID, z.Zone \n",
    "ORDER BY count_zone\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafa077-4154-4ae3-8f1c-7cd51e20b3a4",
   "metadata": {},
   "source": [
    "The lowest count is Jamaica Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66202c-3dd3-4959-bc53-a65d1da3b2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
